{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "873982e3-e7f9-48c9-bc4d-71a8dd329250",
   "metadata": {},
   "source": [
    "# BORA.jl + Turing.jl tutorial: Bayesian BAO inference from 2PCF multipoles\n",
    "\n",
    "This notebook is a **guided, step-by-step** tutorial showing how to run a standard BAO fit in configuration space using:\n",
    "\n",
    "- **BORA.jl** as a fast emulator for the BAO template multipoles, and  \n",
    "- **Turing.jl** to perform **Bayesian inference** (e.g. with NUTS/HMC).\n",
    "\n",
    "The workflow is designed to feel familiar to **Python users**:\n",
    "- `using Package` ‚âà `import package`\n",
    "- `Pkg.activate`/`Pkg.instantiate` ‚âà creating/using a virtual environment\n",
    "- `@model ...` in Turing ‚âà defining a probabilistic model (like PyMC/NumPyro)\n",
    "\n",
    "> **Assumptions**\n",
    "> - You have a set of measured 2PCF multipoles (e.g. from mocks) saved as NumPy `.npy` files.\n",
    "> - You have a trained BORA emulator folder containing `weights.npy`, `inminmax.npy`, `outminmax.npy` for each multipole ‚Ñì.\n",
    "> - You want to fit either `(Œ±‚à•, Œ±‚ä•)` or the reparameterized `(Œ±_iso, Œ±_AP)`.\n",
    "\n",
    "---\n",
    "\n",
    "## 0. Directory layout\n",
    "\n",
    "You can keep your project like:\n",
    "\n",
    "```\n",
    "your_project/\n",
    "  Project.toml\n",
    "  Manifest.toml\n",
    "  data/\n",
    "    separations_rebin_5_s_0_200.npy\n",
    "    multipoles_rebin_5_s_0_200.npy\n",
    "  emulator/\n",
    "    0/weights.npy  0/inminmax.npy  0/outminmax.npy\n",
    "    2/weights.npy  2/inminmax.npy  2/outminmax.npy\n",
    "    4/weights.npy  4/inminmax.npy  4/outminmax.npy\n",
    "  outputs/\n",
    "```\n",
    "\n",
    "If your files are arranged differently, just edit the paths in **Section 2**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36cf7cd-0182-49b4-a667-e6091b46dfb0",
   "metadata": {},
   "source": [
    "## 1. Julia environment setup\n",
    "\n",
    "If you are new to Julia:\n",
    "\n",
    "- `Pkg.activate(\".\")` activates the environment in the current folder (like `conda activate`).\n",
    "- `Pkg.instantiate()` installs all packages listed in `Project.toml` / `Manifest.toml`.\n",
    "\n",
    "If you do **not** have a `Project.toml` yet, you can create one with `Pkg.activate(\".\"); Pkg.add(...)`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77434df6-7a59-4e5f-9c9f-7724696b664e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m project at `~/Desktop/work/Bora_tutorial`\n"
     ]
    }
   ],
   "source": [
    "using Pkg\n",
    "# Activate the environment in this notebook\n",
    "Pkg.activate(\".\")\n",
    "\n",
    "# Install missing deps from Project.toml/Manifest.toml (safe to run multiple times)\n",
    "# Pkg.instantiate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f37067f-3f29-45d6-8b41-c7f5e0eef13e",
   "metadata": {},
   "source": [
    "## 2. Imports\n",
    "\n",
    "We load the packages used throughout the tutorial.\n",
    "\n",
    "Notes for Python users:\n",
    "- `Statistics.mean`, `LinearAlgebra` etc. are part of Julia's standard library.\n",
    "- `NPZ.jl` reads/writes NumPy `.npy/.npz`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b422e2a-703b-49af-9f0d-9ffbf4e25f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Statistics, LinearAlgebra, Random  # Standard libraries\n",
    "using NPZ                                # To read/write NumPy files .npy/.npz \n",
    "using DataInterpolations                 # To perform interpolation of BORA output on the desired separation grid\n",
    "\n",
    "using Plots                              # Plotting libraries\n",
    "\n",
    "using Distributions                      # Statistics and bayesian inference libraries\n",
    "using Turing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83232039-47fd-41bb-81ee-648c8a07f87c",
   "metadata": {},
   "source": [
    "### BORA.jl\n",
    "\n",
    "This tutorial assumes **BORA.jl** is available in your environment.\n",
    "\n",
    "If you are developing BORA locally you might use, e.g.:\n",
    "```julia\n",
    "Pkg.develop(path=\"../BORA.jl\") \n",
    "```\n",
    "\n",
    "Otherwise you can install it from GitHub:\n",
    "```julia\n",
    "Pkg.add(url=\"https://github.com/CosmologicalEmulators/Bora.jl.git\") \n",
    "```\n",
    "\n",
    "<img src=\"gorTqd.png\"\n",
    "     style=\"display: block; margin-left: auto; margin-right: auto;\"\n",
    "     width=\"200\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "723aaef7-b88c-4eed-9144-4d577102ce61",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Bora\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8471626f-21c7-48b3-ad65-f93eb8952b4c",
   "metadata": {},
   "source": [
    "## 3. Helper utilities used in the pipeline\n",
    "\n",
    "Below we include some helper functions that have been placed in utility files:\n",
    "- `utils.jl` --> data loading, covariance corrections, emulator I/O\n",
    "- `plotting_utils.jl` --> input measurements and best-fit/posterior mean model plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "901018b0-4ca6-4800-ba86-55bed3b41dfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "plot_bestfit (generic function with 1 method)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "include(\"utils.jl\")\n",
    "include(\"plotting_utils.jl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b7dcaa-9c27-447a-ab0f-1f211e082023",
   "metadata": {},
   "source": [
    "## 4. Load the BORA emulator\n",
    "\n",
    "BORA emulates the BAO template multipoles (from BAOFit) on a separation grid `s_test`.\n",
    "We typically use a grid that is:\n",
    "- broad enough to support interpolation onto the data grid `s`,\n",
    "- somewhat denser in the BAO region.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e50eb7e-7a1f-46c8-b68f-6872db8a1c58",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "ArgumentError: Package SimpleChains not found in current path.\n- Run `import Pkg; Pkg.add(\"SimpleChains\")` to install the SimpleChains package.",
     "output_type": "error",
     "traceback": [
      "ArgumentError: Package SimpleChains not found in current path.\n- Run `import Pkg; Pkg.add(\"SimpleChains\")` to install the SimpleChains package.",
      "",
      "Stacktrace:",
      " [1] \u001b[0m\u001b[1mmacro expansion\u001b[22m",
      "\u001b[90m   @\u001b[39m \u001b[90m./\u001b[39m\u001b[90m\u001b[4mloading.jl:2403\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m",
      " [2] \u001b[0m\u001b[1mmacro expansion\u001b[22m",
      "\u001b[90m   @\u001b[39m \u001b[90m./\u001b[39m\u001b[90m\u001b[4mlock.jl:376\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m",
      " [3] \u001b[0m\u001b[1m__require\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90minto\u001b[39m::\u001b[0mModule, \u001b[90mmod\u001b[39m::\u001b[0mSymbol\u001b[0m\u001b[1m)\u001b[22m",
      "\u001b[90m   @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m./\u001b[39m\u001b[90m\u001b[4mloading.jl:2386\u001b[24m\u001b[39m",
      " [4] \u001b[0m\u001b[1mrequire\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90minto\u001b[39m::\u001b[0mModule, \u001b[90mmod\u001b[39m::\u001b[0mSymbol\u001b[0m\u001b[1m)\u001b[22m",
      "\u001b[90m   @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m./\u001b[39m\u001b[90m\u001b[4mloading.jl:2362\u001b[24m\u001b[39m",
      " [5] \u001b[0m\u001b[1meval\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mm\u001b[39m::\u001b[0mModule, \u001b[90me\u001b[39m::\u001b[0mAny\u001b[0m\u001b[1m)\u001b[22m",
      "\u001b[90m   @\u001b[39m \u001b[90mCore\u001b[39m \u001b[90m./\u001b[39m\u001b[90m\u001b[4mboot.jl:489\u001b[24m\u001b[39m"
     ]
    }
   ],
   "source": [
    "using SimpleChains\n",
    "using Static\n",
    "using JSON\n",
    "import JSON.parsefile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09055228-fc82-4461-9d1c-3f4c6b10f2e8",
   "metadata": {},
   "source": [
    "#TODO: The following functions will be implemented directly in BORA so users do not need to define them manually. \\\n",
    "The MLP architecture will be read from a `setup.json` file defined during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c53b19f-5b39-46e8-8c8e-1e526b4e6c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39müîÑ Loading BORA emulator\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m‚úÖ Loading completed\n"
     ]
    }
   ],
   "source": [
    "# Load emulators for ‚Ñì=0,2,4 into a \"CompleteEmulator\"\n",
    "emul_path   = \"trained_BORA_150000_100points_Sigma_s_5000_256_Dnorm\"\n",
    "Œæ‚Ñì_emu = Bora.load_complete_emulator(emul_path);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ab94ae-4a7a-4436-b105-61b94d3ec797",
   "metadata": {},
   "source": [
    "## 5. Load data and build the data vector\n",
    "\n",
    "We define:\n",
    "- the fitting scale range `[smin, smax]`,\n",
    "- which multipoles to fit (`ells`),\n",
    "- and the number of model parameters (needed for covariance corrections like Percival).\n",
    "\n",
    "The example below has:\n",
    "- 7 BAO parameters ($\\alpha$ parameters, $b$, $f$, $\\Sigma$ parameters),\n",
    "- plus 3 polynomial broadband coefficients per multipole."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "614400be-45ae-494f-b297-6dac0eb14535",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -----------------------\n",
    "# User configuration\n",
    "# -----------------------\n",
    "Random.seed!(42)\n",
    "\n",
    "# Dataset labels\n",
    "mock_set = \"ELM\"       # ELM/FLAGSHIP/TR1/... --> which set of mocks\n",
    "recon = \"rec\"      # pre_rec/rec          --> if pre or post reconstruction\n",
    "mock_type = \"correct\"  # correct/measured     --> which type of mocks\n",
    "zbin = \"z1\"            # z1/z2/z3/z4          --> which redshift bin\n",
    "mock_id = 0            # 0 or 1-1000          --> mock ID (0 = mean of mocks; >0 uses that mock index)\n",
    "\n",
    "# Path (EDIT this)\n",
    "data_path   = \"/Users/andreacrespi/Desktop/PhD_project/BAO_euclid/BORA_proj/mocks/$(mock_set)/$(recon)/$(mock_type)/$(zbin)/\"\n",
    "\n",
    "#mkpath(output_path) if the output directory does not already exist\n",
    "\n",
    "# Fit settings\n",
    "smin, smax = 50.0, 150.0\n",
    "‚Ñì_max = 4\n",
    "\n",
    "ells = ‚Ñì_max == 4 ? (0,2,4) :\n",
    "       ‚Ñì_max == 2 ? (0,2)   :\n",
    "       ‚Ñì_max == 0 ? (0,)    :\n",
    "       throw(ArgumentError(\"‚Ñì_max must be 0, 2, or 4.\"))\n",
    "\n",
    "# Parameter count used for covariance corrections\n",
    "N_params = 7 + 3*length(ells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fcd48b5d-a07e-4510-9b8a-1aa3809f433e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39müîÑ Loading data üîÑ\n"
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "SystemError: opening file \"/Users/andreacrespi/Desktop/PhD_project/BAO_euclid/BORA_proj/mocks/ELM/rec/correct/z1/separations_rebin_5_s_0_200.npy\": No such file or directory",
     "output_type": "error",
     "traceback": [
      "SystemError: opening file \"/Users/andreacrespi/Desktop/PhD_project/BAO_euclid/BORA_proj/mocks/ELM/rec/correct/z1/separations_rebin_5_s_0_200.npy\": No such file or directory",
      "",
      "Stacktrace:",
      " [1] \u001b[0m\u001b[1msystemerror\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mp\u001b[39m::\u001b[0mString, \u001b[90merrno\u001b[39m::\u001b[0mInt32; \u001b[90mextrainfo\u001b[39m::\u001b[0mNothing\u001b[0m\u001b[1m)\u001b[22m",
      "\u001b[90m   @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m./\u001b[39m\u001b[90m\u001b[4merror.jl:186\u001b[24m\u001b[39m",
      " [2] \u001b[0m\u001b[1mopen\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mfname\u001b[39m::\u001b[0mString; \u001b[90mlock\u001b[39m::\u001b[0mBool, \u001b[90mread\u001b[39m::\u001b[0mNothing, \u001b[90mwrite\u001b[39m::\u001b[0mNothing, \u001b[90mcreate\u001b[39m::\u001b[0mNothing, \u001b[90mtruncate\u001b[39m::\u001b[0mNothing, \u001b[90mappend\u001b[39m::\u001b[0mNothing\u001b[0m\u001b[1m)\u001b[22m",
      "\u001b[90m   @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m./\u001b[39m\u001b[90m\u001b[4miostream.jl:317\u001b[24m\u001b[39m",
      " [3] \u001b[0m\u001b[1mopen\u001b[22m",
      "\u001b[90m   @\u001b[39m \u001b[90m./\u001b[39m\u001b[90m\u001b[4miostream.jl:296\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m",
      " [4] \u001b[0m\u001b[1mnpzread\u001b[22m\u001b[0m\u001b[1m(\u001b[22m::\u001b[0mString\u001b[0m\u001b[1m)\u001b[22m",
      "\u001b[90m   @\u001b[39m \u001b[36mNPZ\u001b[39m \u001b[90m~/.julia/packages/NPZ/UCofn/src/\u001b[39m\u001b[90m\u001b[4mNPZ.jl:271\u001b[24m\u001b[39m",
      " [5] \u001b[0m\u001b[1mLoadData2\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mmocks_path\u001b[39m::\u001b[0mString, \u001b[90ms_min\u001b[39m::\u001b[0mFloat64, \u001b[90ms_max\u001b[39m::\u001b[0mFloat64, \u001b[90mN_params\u001b[39m::\u001b[0mInt64; \u001b[90mells\u001b[39m::\u001b[0mTuple\u001b[90m{Int64, Int64, Int64}\u001b[39m, \u001b[90mmock_id\u001b[39m::\u001b[0mInt64, \u001b[90mcorrect\u001b[39m::\u001b[0mString\u001b[0m\u001b[1m)\u001b[22m",
      "\u001b[90m   @\u001b[39m \u001b[32mMain\u001b[39m \u001b[90m~/Desktop/work/Bora_tutorial/\u001b[39m\u001b[90m\u001b[4mutils.jl:140\u001b[24m\u001b[39m",
      " [6] top-level scope",
      "\u001b[90m   @\u001b[39m \u001b[90m\u001b[4mIn[12]:2\u001b[24m\u001b[39m",
      " [7] \u001b[0m\u001b[1meval\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mm\u001b[39m::\u001b[0mModule, \u001b[90me\u001b[39m::\u001b[0mAny\u001b[0m\u001b[1m)\u001b[22m",
      "\u001b[90m   @\u001b[39m \u001b[90mCore\u001b[39m \u001b[90m./\u001b[39m\u001b[90m\u001b[4mboot.jl:489\u001b[24m\u001b[39m"
     ]
    }
   ],
   "source": [
    "# Load the measurement vector + covariance\n",
    "s, flat_data, covariance = LoadData2(data_path, smin, smax, N_params; ells=ells, mock_id=mock_id, correct=\"hartlap\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d726e95e-8a73-4cce-a108-7e566e44b52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_measurements(s, flat_data, covariance; ells=ells, save_fn = nothing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214f1d9e-1b33-4ffd-adad-9f5b5f843126",
   "metadata": {},
   "source": [
    "## 6. Whitening the data (recommended)\n",
    "\n",
    "For numerical stability in MCMC, it is often convenient to **whiten** the data using the covariance:\n",
    "\n",
    "- Let `Œì = sqrt(C)` such that `C = Œì Œì·µÄ` (matrix square root)\n",
    "- Define `D = Œì‚Åª¬π d` and compare to `Œì‚Åª¬π m(Œ∏)`\n",
    "\n",
    "This is equivalent to the usual Gaussian likelihood but is usually more stable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e87e39-a5e6-4990-9089-7424de030b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Œì = sqrt(covariance)\n",
    "inv_Œì = inv(Œì)\n",
    "D = inv_Œì*flat_data;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe76d9e-1ea7-4ac5-9e84-c50023a568d8",
   "metadata": {},
   "source": [
    "## 7. Define the Turing model\n",
    "\n",
    "Inference model:\n",
    "\n",
    "- Parameters:\n",
    "  - BAO scaling parameters as `(Œ±_ISO, Œ±_AP)` (internally mapped to `Œ±‚à•, Œ±‚ä•`), or directly `(Œ±‚à•, Œ±‚ä•)`\n",
    "  - bias `b`, growth `f`\n",
    "  - damping scales `Œ£`‚Äôs\n",
    "  - polynomial broadband terms for each multipole\n",
    "\n",
    "- Likelihood:\n",
    "  - Gaussian in the whitened space: `D ~ Normal(inv_Œì * model(Œ∏), I)`\n",
    "\n",
    "This matches the standard `œá¬≤` likelihood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f7e057-7aa9-4b2f-a16a-06f5bfe13fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "‚Ñì_to_‚Ñìidx = Dict(0=>1, 2=>2, 4=>3)\n",
    "\n",
    "@model function polyBB_BORAmodel(D, inv_Œì, emu, s, zbin, growth; ells=(0, 2, 4), iso_ap=false)\n",
    "\n",
    "    ‚Ñìidx = getindex.(Ref(‚Ñì_to_‚Ñìidx), collect(ells))\n",
    "\n",
    "    # --- Priors ---\n",
    "    # Some parameters are rescaled to ensure a small condition number of the Gaussian posterior.\n",
    "    \n",
    "    if iso_ap\n",
    "        Œ±ÃÉISO ~ 100*Uniform(0.8, 1.2)\n",
    "        Œ±ÃÉAP ~ 100*Uniform(0.8, 1.2)\n",
    "        Œ±par = (Œ±ÃÉISO/100) * (Œ±ÃÉAP/100)^(2/3)\n",
    "        Œ±perp = (Œ±ÃÉISO/100) * (Œ±ÃÉAP/100)^(-1/3)\n",
    "    else\n",
    "        Œ±ÃÉpar ~ 100*Uniform(0.8, 1.2)\n",
    "        Œ±ÃÉperp ~ 100*Uniform(0.8, 1.2)\n",
    "        Œ±par = Œ±ÃÉpar/100\n",
    "        Œ±perp = Œ±ÃÉperp/100\n",
    "    end\n",
    "    bÃÉ ~ 10*Uniform(0., 5.)  \n",
    "    fÃÉ ~ 10*Uniform(0., 2.)\n",
    "    Œ£par ~ Uniform(0., 20.)\n",
    "    Œ£perp ~ Uniform(0., 20.)\n",
    "    Œ£s ~ Uniform(0., 10.)\n",
    "\n",
    "    lim = 20\n",
    "\n",
    "    B00 ~ Uniform(-lim, lim)\n",
    "    B01 ~ Uniform(-lim, lim)\n",
    "    B02 ~ Uniform(-lim, lim)\n",
    "    \n",
    "    B20 = 0.0; B21 = 0.0; B22 = 0.0\n",
    "    if 2 in ells\n",
    "        B20 ~ Uniform(-lim, lim)\n",
    "        B21 ~ Uniform(-lim, lim)\n",
    "        B22 ~ Uniform(-lim, lim)\n",
    "    end\n",
    "    \n",
    "    B40 = 0.0; B41 = 0.0; B42 = 0.0\n",
    "    if 4 in ells\n",
    "        B40 ~ Uniform(-lim, lim)\n",
    "        B41 ~ Uniform(-lim, lim)\n",
    "        B42 ~ Uniform(-lim, lim)\n",
    "    end\n",
    "\n",
    "    bao_params = [Œ±par, Œ±perp, bÃÉ/10, fÃÉ/10, Œ£par, Œ£perp, Œ£s, get_zeff(zbin)]\n",
    "    bb_params = [B00, B01, B02, B20, B21, B22, B40, B41, B42]\n",
    "\n",
    "    # --- Build model prediction ---\n",
    "    # Emulator provides multipoles on s_test\n",
    "    theory = Bora.get_Œæ‚Ñìs(bao_params, emu)\n",
    "\n",
    "    # Broadband evaluated on the data s grid. \n",
    "    # For now, Bora provides the polynomial broadband only.\n",
    "    # The spline broadband has been already implemented but it needs to be validated and included in the official repository.\n",
    "    BB = Bora.get_broadband(s, bb_params)\n",
    "\n",
    "    # Interpolate emulator prediction to s and add broadband\n",
    "    s_test = emu.rgrid\n",
    "    Œæ_list = [(growth^2) .* DataInterpolations.AkimaInterpolation(view(theory, idx, :), s_test).(s) .+ view(BB, idx, :) for idx in ‚Ñìidx]\n",
    "    interp_Œæ = permutedims(hcat(Œæ_list...))\n",
    "    \n",
    "    flattheory = reshape((interp_Œæ)', (size(inv_Œì)[1],))\n",
    "    \n",
    "    # Whitened model vector\n",
    "    prediction = (inv_Œì * flattheory)\n",
    "\n",
    "    # --- Likelihood ---\n",
    "    D ~ MvNormal(prediction, I)\n",
    "    \n",
    "    return nothing\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05ca3fa-8474-41e9-8433-5b086779bff7",
   "metadata": {},
   "source": [
    "## 8. Analysis example\n",
    "\n",
    "We now run an example analysis, computing best-fit parameters using either the *MAP* or *MLE* (via minimization), and then running an *MCMC chain*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49333b5-d9e3-4398-ab0b-d3a87425173f",
   "metadata": {},
   "source": [
    "### 8.1 Growth factor from BackgroundCosmology Extension\n",
    "\n",
    "Before starting, we note that, since redshift is a free parameter of the emulation, the multipoles are rescaled by $D^2(z)$, the linear growth factor in the fiducial cosmology, which encodes most of the redshift dependence. This reduces the dynamic range of the training targets and improves training efficiency without significantly increasing the number of required training samples. `BORA`‚Äôs predictions are then multiplied by the same factor to recover the physical multipoles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d49aa6d-931f-4aed-a1da-9e94a149f7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The BackgroundCosmology extension is already included in the AbstractCosmologicalEmulators package and is activated by importing \n",
    "#     its dependencies.\n",
    "\n",
    "using AbstractCosmologicalEmulators\n",
    "using OrdinaryDiffEqTsit5\n",
    "using SciMLSensitivity\n",
    "using Integrals\n",
    "using DataInterpolations\n",
    "using LinearAlgebra\n",
    "using FastGaussQuadrature\n",
    "using ForwardDiff\n",
    "using Zygote\n",
    "\n",
    "const ext = Base.get_extension(AbstractCosmologicalEmulators, :BackgroundCosmologyExt)\n",
    "if !isnothing(ext)\n",
    "    using .ext: D_z\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453ead38-ed37-4d82-9836-319e647f17a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Growth factor for the ELM fiducial cosmology: Œ©‚Çò=0.32, h=0.67, mŒΩ=0., w‚ÇÄ=-1., w‚Çê=0.\n",
    "growth = ext.D_z(get_zeff(zbin), 0.32, 0.67; mŒΩ=0., w0=-1, wa=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7f0c0e-6429-4997-a69f-7a9391140171",
   "metadata": {},
   "source": [
    "### 8.2 Instantiation of the posterior model and initial parameter values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f21062-cad9-45ae-ae3d-c3275be0443e",
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_model = polyBB_BORAmodel(D, inv_Œì, Œæ‚Ñì_emu, s, zbin, growth, ells=ells, iso_ap=true);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14751c1-bff0-42cc-872b-08b4b77a43e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_bao_params = rand(MvNormal([100, 100, 15, 1, 5, 5, 5], 0.5*I))\n",
    "initial_bb_params = rand(Normal(0, 1), 3*length(ells))\n",
    "initial_params = vcat(initial_bao_params, initial_bb_params);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9501182a-cf8d-4066-a332-ed6ff7d75e88",
   "metadata": {},
   "source": [
    "### 8.3 Run MAP / MLE\n",
    "\n",
    "The posterior model is entirely ***Automatic Differentiable*** (including `BORA.jl`), so we can leverage optimized, gradient-based minimizers such as L-BFGS (default for `Turing.jl`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c077b1e0-4e28-482c-94ed-e93cac6a6bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "BF_MAP = maximum_a_posteriori(posterior_model; initial_params=initial_params)\n",
    "BF_MLE = maximum_likelihood(posterior_model; initial_params=initial_params);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8946d2e-1caf-4ff2-9d0b-02626add7379",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Minimization convergence: \", BF_MAP.optim_result.retcode, \"\\n\")\n",
    "print(\"Minimization result: \",BF_MAP.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5e52d9-75dd-4d55-b191-371a23690d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best-fit visualization.\n",
    "\n",
    "BF = BF_MLE.values.array\n",
    "\n",
    "‚Ñìidx = getindex.(Ref(‚Ñì_to_‚Ñìidx), collect(ells))\n",
    "\n",
    "iso_ap=true\n",
    "Œ±par = (BF[1]/100) * (BF[2]/100)^(2/3)\n",
    "Œ±perp = (BF[1]/100) * (BF[2]/100)^(-1/3)\n",
    "bao_params = [Œ±par, Œ±perp, BF[3]/10, BF[4]/10, BF[5], BF[6], BF[7], get_zeff(zbin)]\n",
    "\n",
    "bb_params = vcat(BF[8:end], zeros(3*(3-length(ells))))\n",
    "\n",
    "theory = Bora.get_Œæ‚Ñìs(bao_params, Œæ‚Ñì_emu)\n",
    "BB = Bora.get_broadband(s, bb_params)\n",
    "\n",
    "s_test = Œæ‚Ñì_emu.rgrid\n",
    "Œæ_list = [(growth^2) .* DataInterpolations.AkimaInterpolation(view(theory, idx, :), s_test).(s) .+ view(BB, idx, :) for idx in ‚Ñìidx]\n",
    "interp_Œæ = permutedims(hcat(Œæ_list...))\n",
    "\n",
    "best_fit = interp_Œæ\n",
    "\n",
    "plot_bestfit(s, flat_data, covariance, best_fit; ells=ells, save_fn = nothing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850a21a9-850d-41b0-a1e9-ba1459953394",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Goodness-of-fit: œá¬≤\n",
    "model_flat = reduce(vcat, [best_fit[i, :] for i in 1:size(best_fit, 1)])\n",
    "chi2, chi2red = chisq(flat_data, model_flat, Matrix(covariance); nparams=N_params)\n",
    "@info \"chi2 = $chi2, chi2/dof = $chi2red\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670ea922-1e7f-4df6-b6e3-f10bc7d70f5a",
   "metadata": {},
   "source": [
    "### 8.4 Run MCMC chain\n",
    "For MCMC we use `Turing.NUTS(0.75)` (similar to HMC/NUTS in PyMC/Stan), with 0.75 as target acceptance rate.\n",
    "\n",
    "- `n_steps`: number of posterior samples per chain\n",
    "- `n_adapts`: warm-up / adaptation steps\n",
    "- `n_chains`: number of parallel chains (use threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad54ee1-37d8-4838-86f4-e9044ab678ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MCMC settings\n",
    "n_chains = 2\n",
    "n_steps  = 1_000\n",
    "\n",
    "# Sampler\n",
    "nuts = Turing.NUTS(0.75)\n",
    "\n",
    "# Tip: enable multithreading by starting Julia with JULIA_NUM_THREADS=8\n",
    "n_threads = Threads.nthreads()\n",
    "@info \"Number of available threads\" n_threads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8bba8a-aeb0-49b3-aacb-6d4899de7bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "chains = sample(posterior_model, nuts, MCMCThreads(), n_steps, n_chains; progress=true, dialog=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be0977d-db28-4373-815e-fcf482048379",
   "metadata": {},
   "source": [
    "We compute now:\n",
    "\n",
    "- summary statistics (mean/std, ESS, R-hat)\n",
    "- quantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c6721b-e7fc-43ad-ada6-2c1395667e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using MCMCChains\n",
    "\n",
    "summ = summarystats(chains)\n",
    "display(summ[:, [:mean, :std, :ess_bulk, :rhat]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679f5b15-e720-4bf8-acc0-6dd628a82f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "qs = quantile(chains, q=[0.1587, 0.5, 0.8413])\n",
    "display(qs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde1c037-60f8-400a-8039-e8245ead98b1",
   "metadata": {},
   "source": [
    "### 8.5 Saving results\n",
    "\n",
    "We save:\n",
    "- raw cha\"in array (NumPy `.npy`) to use Python plotting libraries, such as GetDist\n",
    "- summary stats and quantiles\n",
    "\n",
    "You can load the saved arrays in Python with `numpy.load(...)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8db793-4b4d-4ee4-bee7-2d2f09c7609b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save stack chains to NumPy\n",
    "output_path = \"/Users/andreacrespi/Desktop/PhD_project/BAO_euclid/BORA_proj/tutorial/\"\n",
    "\n",
    "chain_array = reduce(vcat, [chains.value.data[:, :, i] for i in 1:n_chains])\n",
    "npzwrite(joinpath(output_path, \"bao_polyBB_chains.npy\"), chain_array)\n",
    "\n",
    "diagnostics = summ[:, [:mean, :std, :ess_bulk, :rhat]][:, :]\n",
    "quantiles = qs[:, :]\n",
    "npzwrite(joinpath(output_path, \"bao_polyBB_sumstats.npy\"), Matrix{Float64}(diagnostics))\n",
    "npzwrite(joinpath(output_path, \"bao_polyBB_quantiles.npy\"), Matrix{Float64}(quantiles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3814a08b-e857-4160-9bcb-8ed6f5beaa2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.12",
   "language": "julia",
   "name": "julia-1.12"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
